{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from os import listdir\n",
    "import codecs\n",
    "import pickle\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import tensor_array_ops\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasePreprocessor:\n",
    "    \"\"\"The abstract class for a preprocessor. You should subclass\n",
    "    this and implement the methods actions and result, and possibly\n",
    "    __init__, goal_test, and path_cost. Then you will create instances\n",
    "    of your subclass and solve them with the various search functions.\"\"\"\n",
    "    \n",
    "    # List of contractions.\n",
    "    CONTRACTION_LIST = {\n",
    "            \"ain't\": \"is not\",\n",
    "            \"aren't\": \"are not\",\n",
    "            \"can't\": \"cannot\",\n",
    "            \"can't've\": \"cannot have\",\n",
    "            \"'cause\": \"because\",\n",
    "            \"could've\": \"could have\",\n",
    "            \"couldn't\": \"could not\",\n",
    "            \"couldn't've\": \"could not have\",\n",
    "            \"didn't\": \"did not\",\n",
    "            \"doesn't\": \"does not\",\n",
    "            \"don't\": \"do not\",\n",
    "            \"hadn't\": \"had not\",\n",
    "            \"hadn't've\": \"had not have\",\n",
    "            \"hasn't\": \"has not\",\n",
    "            \"haven't\": \"have not\",\n",
    "            \"he'd\": \"he would\",\n",
    "            \"he'd've\": \"he would have\",\n",
    "            \"he'll\": \"he will\",\n",
    "            \"he'll've\": \"he he will have\",\n",
    "            \"he's\": \"he is\",\n",
    "            \"how'd\": \"how did\",\n",
    "            \"how'd'y\": \"how do you\",\n",
    "            \"how'll\": \"how will\",\n",
    "            \"how's\": \"how is\",\n",
    "            \"I'd\": \"I would\",\n",
    "            \"I'd've\": \"I would have\",\n",
    "            \"I'll\": \"I will\",\n",
    "            \"I'll've\": \"I will have\",\n",
    "            \"I'm\": \"I am\",\n",
    "            \"I've\": \"I have\",\n",
    "            \"i'd\": \"i would\",\n",
    "            \"i'd've\": \"i would have\",\n",
    "            \"i'll\": \"i will\",\n",
    "            \"i'll've\": \"i will have\",\n",
    "            \"i'm\": \"i am\",\n",
    "            \"i've\": \"i have\",\n",
    "            \"isn't\": \"is not\",\n",
    "            \"it'd\": \"it would\",\n",
    "            \"it'd've\": \"it would have\",\n",
    "            \"it'll\": \"it will\",\n",
    "            \"it'll've\": \"it will have\",\n",
    "            \"it's\": \"it is\",\n",
    "            \"let's\": \"let us\",\n",
    "            \"ma'am\": \"madam\",\n",
    "            \"mayn't\": \"may not\",\n",
    "            \"might've\": \"might have\",\n",
    "            \"mightn't\": \"might not\",\n",
    "            \"mightn't've\": \"might not have\",\n",
    "            \"must've\": \"must have\",\n",
    "            \"mustn't\": \"must not\",\n",
    "            \"mustn't've\": \"must not have\",\n",
    "            \"needn't\": \"need not\",\n",
    "            \"needn't've\": \"need not have\",\n",
    "            \"o'clock\": \"of the clock\",\n",
    "            \"oughtn't\": \"ought not\",\n",
    "            \"oughtn't've\": \"ought not have\",\n",
    "            \"shan't\": \"shall not\",\n",
    "            \"sha'n't\": \"shall not\",\n",
    "            \"shan't've\": \"shall not have\",\n",
    "            \"she'd\": \"she would\",\n",
    "            \"she'd've\": \"she would have\",\n",
    "            \"she'll\": \"she will\",\n",
    "            \"she'll've\": \"she will have\",\n",
    "            \"she's\": \"she is\",\n",
    "            \"should've\": \"should have\",\n",
    "            \"shouldn't\": \"should not\",\n",
    "            \"shouldn't've\": \"should not have\",\n",
    "            \"so've\": \"so have\",\n",
    "            \"so's\": \"so as\",\n",
    "            \"that'd\": \"that would\",\n",
    "            \"that'd've\": \"that would have\",\n",
    "            \"that's\": \"that is\",\n",
    "            \"there'd\": \"there would\",\n",
    "            \"there'd've\": \"there would have\",\n",
    "            \"there's\": \"there is\",\n",
    "            \"they'd\": \"they would\",\n",
    "            \"they'd've\": \"they would have\",\n",
    "            \"they'll\": \"they will\",\n",
    "            \"they'll've\": \"they will have\",\n",
    "            \"they're\": \"they are\",\n",
    "            \"they've\": \"they have\",\n",
    "            \"to've\": \"to have\",\n",
    "            \"wasn't\": \"was not\",\n",
    "            \"we'd\": \"we would\",\n",
    "            \"we'd've\": \"we would have\",\n",
    "            \"we'll\": \"we will\",\n",
    "            \"we'll've\": \"we will have\",\n",
    "            \"we're\": \"we are\",\n",
    "            \"we've\": \"we have\",\n",
    "            \"weren't\": \"were not\",\n",
    "            \"what'll\": \"what will\",\n",
    "            \"what'll've\": \"what will have\",\n",
    "            \"what're\": \"what are\",\n",
    "            \"what's\": \"what is\",\n",
    "            \"what've\": \"what have\",\n",
    "            \"when's\": \"when is\",\n",
    "            \"when've\": \"when have\",\n",
    "            \"where'd\": \"where did\",\n",
    "            \"where's\": \"where is\",\n",
    "            \"where've\": \"where have\",\n",
    "            \"who'll\": \"who will\",\n",
    "            \"who'll've\": \"who will have\",\n",
    "            \"who's\": \"who is\",\n",
    "            \"who've\": \"who have\",\n",
    "            \"why's\": \"why is\",\n",
    "            \"why've\": \"why have\",\n",
    "            \"will've\": \"will have\",\n",
    "            \"won't\": \"will not\",\n",
    "            \"won't've\": \"will not have\",\n",
    "            \"would've\": \"would have\",\n",
    "            \"wouldn't\": \"would not\",\n",
    "            \"wouldn't've\": \"would not have\",\n",
    "            \"y'all\": \"you all\",\n",
    "            \"y'all'd\": \"you all would\",\n",
    "            \"y'all'd've\": \"you all would have\",\n",
    "            \"y'all're\": \"you all are\",\n",
    "            \"y'all've\": \"you all have\",\n",
    "            \"you'd\": \"you would\",\n",
    "            \"you'd've\": \"you would have\",\n",
    "            \"you'll\": \"you will\",\n",
    "            \"you'll've\": \"you will have\",\n",
    "            \"you're\": \"you are\",\n",
    "            \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"The constructor. Your subclass's constructor can add\n",
    "        other arguments.\"\"\"\n",
    "        \n",
    "    def cleanData(self, text, removeStopwords = True):\n",
    "        \"\"\"\n",
    "        This method is a standard implementation to clean any text that are\n",
    "        passed in as parameter. Here the text is split into sentences and each\n",
    "        sentence is in turn cleaned by invoking the cleanSentence() method.\n",
    "        \n",
    "        Any custom cleaning needs to be done at the subclass Preprocessor and\n",
    "        the invoke this method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : string\n",
    "            The text to be cleaned.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        string\n",
    "            The cleaned text.\n",
    "        punctuationsToBeExcluded : list\n",
    "            List of any particular punctuations to be ignored when cleaning \n",
    "            the sentence.\n",
    "\n",
    "        \"\"\"\n",
    "        cleanedSentences = list()\n",
    "        sentences = text.split('\\n')\n",
    "        for sentence in sentences:\n",
    "            # Cleaning the sentence here\n",
    "            sentence = self.cleanSentence(sentence, removeStopwords)\n",
    "            if len(sentence) > 0:\n",
    "                cleanedSentences.append(sentence)\n",
    "        return ' '.join(cleanedSentences).lower()\n",
    "        \n",
    "    def cleanSentence(self, sentence, removeStopwords):\n",
    "        \"\"\"\n",
    "        The method cleans a passed in sentence parameter by:\n",
    "            i. removing all whitespace characters.\n",
    "            ii. removing all punctuations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentence : string\n",
    "            The sentence to be cleaned.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        string\n",
    "            The cleaned sentence.\n",
    "\n",
    "        \"\"\"\n",
    "        sentence = sentence.lower()\n",
    "        sentence = self.fixContractions(sentence)\n",
    "        sentence = self.removeUnwantedCharacters(sentence)\n",
    "        if removeStopwords:\n",
    "            sentence = self.removeStopWords(sentence)\n",
    "        return sentence\n",
    "    \n",
    "    def fixContractions(self, text, contractionList=CONTRACTION_LIST):\n",
    "        \"\"\"\n",
    "        # Expands the contractions by finding a match in the Contraction list \n",
    "        Regular expression pattern matching.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : string\n",
    "            The text where contractions need to be fixed.\n",
    "        contraction_list : dictionary, optional\n",
    "            The dictionary which tells the mapping for different types of \n",
    "            contractions. The default is CONTRACTION_LIST.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        string\n",
    "            The expanded text.\n",
    "\n",
    "        \"\"\"\n",
    "        text = re.findall(r\"[\\w']+\", text)\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractionList:\n",
    "                new_text.append(contractionList[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        return ' '.join(new_text)\n",
    "    \n",
    "    def removeUnwantedCharacters(self, text):\n",
    "        \"\"\"\n",
    "        Removes all unwanted characters from the text.\n",
    "        This includes any URLs, HTML tags, punctuations, line breaks.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : string\n",
    "            The text that needs to be cleaned.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        text : string\n",
    "            The cleaned text.\n",
    "\n",
    "        \"\"\"\n",
    "        text = text.strip()\n",
    "        text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)# remove links\n",
    "        text = re.sub(r'\\<a href', ' ', text)# remove html link tag\n",
    "        text = re.sub(r'&amp;', '', text) \n",
    "        text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "        text = re.sub(r'<br />', ' ', text)\n",
    "        text = re.sub(r'\\'', ' ', text)\n",
    "        return text\n",
    "    \n",
    "    def removeStopWords(self, text):\n",
    "        \"\"\"\n",
    "        Removes the stop words.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : string\n",
    "            The text where the stop words need to be removed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        string\n",
    "            The stop words removed text.\n",
    "\n",
    "        \"\"\"\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnPreprocessor(BasePreprocessor):\n",
    "    \"\"\"This is a preprocessor class which implements CNN dataset specific\n",
    "    cleaning methods.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The constructor method to do any initial value setting.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        CnnProcessor class object.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "            \n",
    "    def stripOffNewsSource(self, text):\n",
    "        \"\"\"\n",
    "        This method helps to strip off the news source from the text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : string\n",
    "            The news text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        text : string\n",
    "            The news text with any news source stripped off.\n",
    "\n",
    "        \"\"\"\n",
    "        closingBracketIndex = text.find(')')\n",
    "        firstWord = ''\n",
    "        if closingBracketIndex > -1:\n",
    "            firstWordToBeExcluded = False\n",
    "            countOfSpaceChar = 0\n",
    "            for i in range(closingBracketIndex-1,-1,-1):\n",
    "                if text[i] == ' ':\n",
    "                    if countOfSpaceChar < 4:\n",
    "                        countOfSpaceChar += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        firstWordToBeExcluded = False\n",
    "                        break\n",
    "                elif text[i] == '(' and not firstWordToBeExcluded:\n",
    "                    countOfSpaceChar = 0\n",
    "                    firstWordToBeExcluded = True\n",
    "            \n",
    "            if firstWordToBeExcluded:\n",
    "                firstWord = text[:closingBracketIndex + 1]\n",
    "                text = text[len(firstWord):].strip()\n",
    "        return text\n",
    "    \n",
    "    def cleanData(self, text, isSummary):\n",
    "        \"\"\"\n",
    "        This method helps to clean any text by calling the cleanData from the base\n",
    "        class. \n",
    "        \n",
    "        The CNN dataset files can have the source of the news at the start of\n",
    "        the file in brackets. It iss wise to remove this as part of the cleaning\n",
    "        as this source name doesn't help with the actual summarisation task.\n",
    "        Hence another method called stripOffNewsSource() is invoked before\n",
    "        before calling the cleanData() method in the base class.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text : string\n",
    "            The text to be cleaned.\n",
    "        isSummary : boolean\n",
    "            Denotes whether the text to be cleaned is actual News text or \n",
    "            the summary.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        string\n",
    "            The cleaned text.\n",
    "\n",
    "        \"\"\"\n",
    "        # If the text is not a summary, then strip of the news source from\n",
    "        # the text\n",
    "        if not isSummary:\n",
    "            text = self.stripOffNewsSource(text)\n",
    "        \n",
    "        # Invoking the standard cleanData method.\n",
    "        return super().cleanData(text, not isSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of base class for the data loader.\n",
    "\"\"\"\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Class to help with the loading of data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cleanDataOp):\n",
    "        \"\"\"\n",
    "        The constructor method to do any initial value setting.\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataLoader class object.\n",
    "\n",
    "        \"\"\"\n",
    "        self.cleanDataOp = cleanDataOp\n",
    "    \n",
    "    def loadSourceDocument(self, filePath):\n",
    "        \"\"\"\n",
    "        Loads the contents of a single source document\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filePath : string\n",
    "            The file path of the source document.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        text : string\n",
    "            The loaded text.\n",
    "\n",
    "        \"\"\"\n",
    "        file = open(filePath, encoding='utf-8')\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text\n",
    "        \n",
    "    def loadSourceDocuments(self, sourceDirectoryPath, refreshSourceDocs):\n",
    "        \"\"\"\n",
    "        This method helps to load the source documents.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sourceDirectoryPath : string\n",
    "            Directory path where the source files reside.\n",
    "        refreshSourceDocs : bool\n",
    "            If this parameter is true, all the source files are read fresh else\n",
    "            already pickled file is loaded.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List of dictionaries holding the loaded text and summaries.\n",
    "\n",
    "        \"\"\"\n",
    "        all_text = {}\n",
    "        all_text['Text'] = []\n",
    "        all_text['Summary'] = []\n",
    "        if refreshSourceDocs:\n",
    "            fileIndex = 1\n",
    "            for name in listdir(sourceDirectoryPath):\n",
    "                if not name.startswith('._'):\n",
    "                    filePath = sourceDirectoryPath + '/' + name\n",
    "                    # load document\n",
    "                    doc = self.loadSourceDocument(filePath)\n",
    "                    text, summary = self.retrieveTextAndSummary(doc)\n",
    "                    all_text['Text'].append(self.cleanDataOp(text, False))\n",
    "                    all_text['Summary'].append(self.cleanDataOp(summary, True))\n",
    "                    print('Extracted and cleaned file number', fileIndex, '=>', name)\n",
    "                    fileIndex += 1\n",
    "        return all_text\n",
    "        \n",
    "    def retrieveTextAndSummary(self, document):\n",
    "        \"\"\"\n",
    "        This method helps separate the actual text and summary from the whole\n",
    "        CNN news document.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        document : string\n",
    "            The content of the news story file from which the actual text and\n",
    "            summary needs to be separated.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        string\n",
    "            The text and a list of summaries.\n",
    "\n",
    "        \"\"\"\n",
    "        # All the summaries in the document are starting with the '@highlight'\n",
    "        # phrase.\n",
    "        textIndex = document.find('@highlight')\n",
    "        \n",
    "        # Splitting the actual text content and the summary lines\n",
    "        text, summaries = document[:textIndex], document[textIndex:].split('@highlight')\n",
    "        \n",
    "        # Stripping all the whitespaces from each of the summary lines.\n",
    "        summaries = [s.strip() for s in summaries if len(s) > 0]\n",
    "        \n",
    "        # Returning the actual text and the list of summaries\n",
    "        return text, ' '.join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of base class for the Word Embedding framework.\n",
    "\"\"\"\n",
    "class WordEmbeddingBase:\n",
    "    \"\"\"The base class for Word Embedding framework.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embeddingsDimension, specialTokens):\n",
    "        \"\"\"The constructor. Your subclass's constructor can add\n",
    "        other arguments.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        WordEmbeddingBase object.\n",
    "\n",
    "        \"\"\"\n",
    "        self.embeddingsDimension = embeddingsDimension\n",
    "        self.specialTokens = specialTokens\n",
    "    \n",
    "    def constructEmbeddingsIndex(self):\n",
    "        \"\"\"\n",
    "        The method to build the embedding index using the vector file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        embedding_index : dictionary\n",
    "            The word to vector data mapping.\n",
    "\n",
    "        \"\"\"\n",
    "        embeddingsIndex = {}\n",
    "        with codecs.open(self.vectorFilePath, 'r', 'utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                sr = line.split()\n",
    "                word = sr[0]\n",
    "                embedding = np.asarray(sr[1:], dtype='float32')\n",
    "                embeddingsIndex[word] = embedding\n",
    "        return embeddingsIndex\n",
    "        \n",
    "    def buildEmbeddingsVectorMatrix(self, wordToIntDict, embeddingsIndex):\n",
    "        \"\"\"\n",
    "        The method to build the embedding index using the vector file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        embeddingDimension : number\n",
    "            The dimension of embedding used.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        embeddingMatrix : dictionary\n",
    "            The mapping from integer representation of the word to the \n",
    "            embedding vector.\n",
    "\n",
    "        \"\"\"\n",
    "        embeddingsMatrix = np.zeros((len(wordToIntDict), self.embeddingsDimension), dtype=np.float32)\n",
    "        for word, i in wordToIntDict.items():\n",
    "            embeddingsVector = embeddingsIndex.get(word)\n",
    "            if embeddingsVector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embeddingsMatrix[i] = embeddingsVector\n",
    "            else:\n",
    "                randomGeneratedEmbeddingsVector = np.array(np.random.uniform(-1.0, 1.0, self.embeddingsDimension))\n",
    "                embeddingsIndex[word] = randomGeneratedEmbeddingsVector\n",
    "                embeddingsMatrix[i] = randomGeneratedEmbeddingsVector\n",
    "        return embeddingsMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of custom class for the Glove Word Embedding framework.\n",
    "\"\"\"\n",
    "class GloveEmbedding(WordEmbeddingBase):\n",
    "    \"\"\"The custom class for Glove Word Embedding framework.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embeddingsDimension, specialTokens):\n",
    "        \"\"\"\n",
    "        The constructor to do any initial value setting.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        GloveEmbedding class object.\n",
    "\n",
    "        \"\"\"\n",
    "        self.vectorFilePath = 'embeddings/glove.6B.50d.txt'\n",
    "        super().__init__(embeddingsDimension, specialTokens)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of custom class for the Conceptnet Numberbatch's Embedding framework.\n",
    "\"\"\"\n",
    "class ConceptNetEmbedding(WordEmbeddingBase):\n",
    "    \"\"\"The custom class for Coneptnet Numberbatch's Embedding framework.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embeddingsDimension, specialTokens):\n",
    "        \"\"\"\n",
    "        The constructor to do any initial value setting.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        GloveEmbedding class object.\n",
    "\n",
    "        \"\"\"\n",
    "        self.vectorFilePath = 'embeddings/numberbatch-en-19.08.txt'\n",
    "        super().__init__(embeddingsDimension, specialTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    \"\"\"A Utility class for some static helper methods\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def pickle(filename, contents):\n",
    "        \"\"\"\n",
    "        This method pickles the contents to a file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : string\n",
    "            The pickle file location.\n",
    "        contents : string\n",
    "            The contents to be pickled.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        file = open(filename, \"wb\")\n",
    "        pickle.dump(contents, file)\n",
    "        file.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def unPickle(filename):\n",
    "        \"\"\"\n",
    "        This method loads the contents from a pickled file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : string\n",
    "            The pickle file location.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The contents from a pickled file.\n",
    "\n",
    "        \"\"\"\n",
    "        file = open(filename,\"rb\")\n",
    "        contents = pickle.load(file)\n",
    "        file.close()\n",
    "        return contents\n",
    "    \n",
    "    @staticmethod\n",
    "    def countWords(wordsCountDict, text):\n",
    "        \"\"\"\n",
    "        This method returns a dictionary with the words to number of occurrences\n",
    "        mapping.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        wordsCountDict : dictionary\n",
    "            Word to number of occurrences mapping.\n",
    "        text : string\n",
    "            The text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        for sentence in text:\n",
    "            for word in sentence.split():\n",
    "                if word not in wordsCountDict:\n",
    "                    wordsCountDict[word] = 1\n",
    "                else:\n",
    "                    wordsCountDict[word] += 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def buildWordToNumberRepresentations(wordsCountDict, specialTokens, embeddingsIndex, thresholdForRareWordsCount):\n",
    "        \"\"\"\n",
    "        This method returns two dictionaries with a word to number mapping and another one with number to word \n",
    "        mapping.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        wordsCountDict : dictionary\n",
    "            Word to number of occurrences mapping.\n",
    "        specialTokens: dictionary\n",
    "            Special tokens to number mapping\n",
    "        embeddingsIndex: dictionary\n",
    "            The dictionary which has the mapping from a word to corresponding embedding vector. This dictionary\n",
    "            is normally constructed from a word embeddings vector file.\n",
    "        thresholdForRareWordsCount : int\n",
    "            Only those words with frequencies above this threshold are considered if they are not part of\n",
    "            the embeddings index dictionary.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Two dictionaries:\n",
    "            i. Word to Number mapping\n",
    "            ii. Number to Word mapping\n",
    "\n",
    "        \"\"\"\n",
    "        wordToIntDict = {}\n",
    "        intToWordDict = {}\n",
    "        wordIndex = 0\n",
    "        for word, count in wordsCountDict.items():\n",
    "            if count >= thresholdForRareWordsCount or word in embeddingsIndex:\n",
    "                wordToIntDict[word] = wordIndex\n",
    "                intToWordDict[wordIndex] = word\n",
    "                wordIndex += 1\n",
    "        \n",
    "        for token in specialTokens.values():\n",
    "            wordToIntDict[token] = wordIndex\n",
    "            intToWordDict[wordIndex] = token\n",
    "            wordIndex += 1\n",
    "        \n",
    "        return wordToIntDict, intToWordDict\n",
    "    \n",
    "    @staticmethod\n",
    "    def convertTextToNumberSequence(text, wordToIntDict, unknownToken, eosToken = None, applyEos = False):\n",
    "        \"\"\"\n",
    "        This method converts a text to a sequence of numbers based on the word to integer mapping dictionary.\n",
    "        If a word does not exist in the word to integer mapping dictionary, a number representation of 'Unknown'\n",
    "        special token is used instead.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        wordToIntDict : dictionary\n",
    "            Word to number of  mapping.\n",
    "        unknownToken: string\n",
    "            The 'Unknown' specal token string.\n",
    "        eosToken: number\n",
    "            The 'End of Sequence' special token string.\n",
    "        applyEos : boolean\n",
    "            If true, at the end of the number sequence the number corresponding to 'End of Sequence' special token\n",
    "            shall be appended. \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        i. The sequence of numbers\n",
    "        ii. Total words count\n",
    "        iii. Total unknown words count\n",
    "        \"\"\"\n",
    "        numberSequenceForText = []\n",
    "        wordsCount = 0\n",
    "        unknownWordsCount = 0\n",
    "        for sentence in text:\n",
    "            numberSequenceForSentence = []\n",
    "            for word in sentence.split():\n",
    "                wordsCount += 1\n",
    "                if word in wordToIntDict:\n",
    "                    numberSequenceForSentence.append(wordToIntDict[word])\n",
    "                else:\n",
    "                    numberSequenceForSentence.append(wordToIntDict[unknownToken])\n",
    "                    unknownWordsCount += 1\n",
    "            \n",
    "            if applyEos and eosToken is not None:\n",
    "                numberSequenceForSentence.append(wordToIntDict[eosToken])\n",
    "            numberSequenceForText.append(numberSequenceForSentence)\n",
    "        return numberSequenceForText, wordsCount, unknownWordsCount\n",
    "    \n",
    "    @staticmethod       \n",
    "    def applyFilterAndSort(summariesAndTextZippedList, summaryAndTextAttributes):\n",
    "        \"\"\"\n",
    "        Filter method to filter out summary and text zipped entry based on maximum Summary Length, \n",
    "        maximum Text length, unknown word limit in summaries and unknown word limit in text.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        summariesAndTextZippedList: list\n",
    "            List of zipped version of Summary and Text\n",
    "        summaryAndTextAttributes : dictionary\n",
    "            Carries:\n",
    "                i. The maximum number of words allowed in a Summary\n",
    "                ii. The maximum number of words allowed in a Text\n",
    "                i. The minimum number of words required in a Summary\n",
    "                ii. The minimum number of words required in a Text\n",
    "                iii. The maximum number of unknown words allowed in a Summary\n",
    "                iv. The maximum number of unknown words allowed in a Text\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        i. The sequence of numbers\n",
    "        ii. Total words count\n",
    "        iii. Total unknown words count\n",
    "        \"\"\"\n",
    "        maximumSummaryLength = summaryAndTextAttributes['maximumSummaryLength']\n",
    "        maximumTextLength = summaryAndTextAttributes['maximumTextLength']\n",
    "        minimumSummaryLength = summaryAndTextAttributes['minimumSummaryLength']\n",
    "        minimumTextLength = summaryAndTextAttributes['minimumTextLength']\n",
    "        unknownsInSummaryLimit = summaryAndTextAttributes['unknownsInSummaryLimit']\n",
    "        unknownsInTextLimit = summaryAndTextAttributes['unknownsInTextLimit']\n",
    "        unknownTokenNumberRepresentation = summaryAndTextAttributes['unknownTokenNumberRepresentation']\n",
    "        \n",
    "        def countUnknowns(sentence, unknownTokenNumberRepresentation):\n",
    "            '''Counts the number of time UNK appears in a sentence.'''\n",
    "            unknownsCount = 0\n",
    "            for word in sentence:\n",
    "                if word == unknownTokenNumberRepresentation:\n",
    "                    unknownsCount += 1\n",
    "            return unknownsCount\n",
    "    \n",
    "        def filterCondition(item):\n",
    "            \"\"\"\n",
    "            Filters an item based on certain conditions.\n",
    "            \"\"\"\n",
    "            summarySeq = item[0]\n",
    "            textSeq = item[1]\n",
    "            if(len(summarySeq) <= maximumSummaryLength and\n",
    "               len(textSeq) <= maximumTextLength and \n",
    "               len(summarySeq) >= minimumSummaryLength and\n",
    "               len(textSeq) >= minimumTextLength and\n",
    "               countUnknowns(summarySeq, unknownTokenNumberRepresentation) <= unknownsInSummaryLimit and \n",
    "               countUnknowns(textSeq, unknownTokenNumberRepresentation) <= unknownsInTextLimit):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "    \n",
    "        filteredSummariesAndText = list(filter(filterCondition, summariesAndTextZippedList))\n",
    "        summariesAndTextSorted = sorted(filteredSummariesAndText, key=lambda entry: len(entry[1]))\n",
    "        summariesAndTextSorted = list(zip(*summariesAndTextSorted))\n",
    "        return list(summariesAndTextSorted[0]), list(summariesAndTextSorted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "sourceDirectoryPath = '../data/cnn/stories'\n",
    "refreshSourceDocs = False\n",
    "pickledFilePath = '../data/cnn_dataset.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Texts 92579\n"
     ]
    }
   ],
   "source": [
    "if refreshSourceDocs:\n",
    "    preprocessor = CnnPreprocessor()\n",
    "    dataLoader = DataLoader(preprocessor.cleanData)\n",
    "    loadedContent = dataLoader.loadSourceDocuments(sourceDirectoryPath, refreshSourceDocs)\n",
    "                \n",
    "    # save to file\n",
    "    Utils.pickle(pickledFilePath, loadedContent)\n",
    "    print('Pickled the cleaned data into the file:', pickledFilePath)\n",
    "\n",
    "# load from file\n",
    "news = Utils.unPickle(pickledFilePath)\n",
    "print('Loaded Texts %d' % len(news['Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedText = news['Text']\n",
    "cleanedSummaries = news['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingsDimension = 50\n",
    "specialTokens = {\n",
    "    'UNKNOWN': '<UNK>',\n",
    "    'PADDING': '<PAD>',\n",
    "    'ENDOFSEQUENCE': '<EOS>',\n",
    "    'STARTOFSEQUENCE': '<GO>'\n",
    "}\n",
    "embedding = GloveEmbedding(embeddingsDimension, specialTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary: 238749\n"
     ]
    }
   ],
   "source": [
    "wordsCountDict = {}\n",
    "Utils.countWords(wordsCountDict, cleanedText)\n",
    "Utils.countWords(wordsCountDict, cleanedSummaries)\n",
    "print(\"Size of Vocabulary:\", len(wordsCountDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingsIndex = embedding.constructEmbeddingsIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words missing from the embedding framework: 992\n",
      "Percent of words that are missing from vocabulary: 0.42%\n"
     ]
    }
   ],
   "source": [
    "missingWordsCount = 0\n",
    "missingWords = []\n",
    "# The below threshold is used to ignore all those words which appear below threshold count in the entire data set\n",
    "thresholdForRareWordsCount = 20\n",
    "for word, count in wordsCountDict.items():\n",
    "    if count > thresholdForRareWordsCount:\n",
    "        if word not in embeddingsIndex:\n",
    "            missingWordsCount += 1\n",
    "            missingWords.append((word, count))\n",
    "            \n",
    "missingRatio = round(missingWordsCount/len(wordsCountDict), 4) * 100\n",
    "\n",
    "print(\"Number of words missing from the embedding framework:\", missingWordsCount)\n",
    "print(\"Percent of words that are missing from vocabulary: {}%\".format(missingRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words: 238749\n",
      "Number of words we will use: 155837\n",
      "Percent of words we will use: 65.27%\n"
     ]
    }
   ],
   "source": [
    "wordToIntDict, intToWordDict = Utils.buildWordToNumberRepresentations(\n",
    "    wordsCountDict, embedding.specialTokens, embeddingsIndex, thresholdForRareWordsCount\n",
    ")\n",
    "\n",
    "usageRatio = round(len(wordToIntDict) / len(wordsCountDict),4)*100\n",
    "\n",
    "print(\"Total number of unique words:\", len(wordsCountDict))\n",
    "print(\"Number of words we will use:\", len(wordToIntDict))\n",
    "print(\"Percent of words we will use: {}%\".format(usageRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of embeddings: 155837\n"
     ]
    }
   ],
   "source": [
    "embeddingsMatrix = embedding.buildEmbeddingsVectorMatrix(wordToIntDict, embeddingsIndex)\n",
    "print('Total number of embeddings:', len(embeddingsMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 39010724\n",
      "Total number of UNKs: 180753\n",
      "Percent of words that are UNK: 0.45999999999999996%\n"
     ]
    }
   ],
   "source": [
    "# Converting all the summaries to corresponding number sequences\n",
    "summariesToNumberSequence, summaryWordsCount, summaryUnknownWordsCount = Utils.convertTextToNumberSequence(\n",
    "    cleanedSummaries, \n",
    "    wordToIntDict, \n",
    "    embedding.specialTokens['UNKNOWN']\n",
    ")\n",
    "\n",
    "# Converting all the text to corresponding number sequences\n",
    "textToNumberSequence, textWordsCount, textUnknownWordsCount = Utils.convertTextToNumberSequence(\n",
    "    cleanedText, \n",
    "    wordToIntDict, \n",
    "    embedding.specialTokens['UNKNOWN'], \n",
    "    eosToken = embedding.specialTokens['ENDOFSEQUENCE'],\n",
    "    applyEos = True\n",
    ")\n",
    "\n",
    "totalWordsCount = summaryWordsCount + textWordsCount\n",
    "totalUnknownWordsCount = summaryUnknownWordsCount + textUnknownWordsCount\n",
    "unknownPercentage = round(totalUnknownWordsCount/totalWordsCount,4) * 100\n",
    "\n",
    "print(\"Total number of words:\", totalWordsCount)\n",
    "print(\"Total number of UNKs:\", totalUnknownWordsCount)\n",
    "print(\"Percent of words that are UNK: {}%\".format(unknownPercentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLengthDataframe(textToNumberSequences):\n",
    "    '''Create a data frame of the sentence lengths from a text'''\n",
    "    lengths = []\n",
    "    for textToNumberSequence in textToNumberSequences:\n",
    "        lengths.append(len(textToNumberSequence))\n",
    "    return pd.DataFrame(lengths, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries:\n",
      "             counts\n",
      "count  92579.000000\n",
      "mean      43.395781\n",
      "std        9.982053\n",
      "min        8.000000\n",
      "25%       36.000000\n",
      "50%       44.000000\n",
      "75%       51.000000\n",
      "max      108.000000\n",
      "\n",
      "Texts:\n",
      "             counts\n",
      "count  92579.000000\n",
      "mean     378.981897\n",
      "std      193.264759\n",
      "min        1.000000\n",
      "25%      228.000000\n",
      "50%      351.000000\n",
      "75%      496.000000\n",
      "max     1454.000000\n"
     ]
    }
   ],
   "source": [
    "lengthSummaries = computeLengthDataframe(summariesToNumberSequence)\n",
    "lengthText = computeLengthDataframe(textToNumberSequence)\n",
    "\n",
    "print(\"Summaries:\")\n",
    "print(lengthSummaries.describe())\n",
    "print()\n",
    "print(\"Texts:\")\n",
    "print(lengthText.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464.0\n",
      "645.0\n",
      "748.0\n",
      "927.2200000000012\n",
      "49.0\n",
      "56.0\n",
      "59.0\n",
      "67.0\n"
     ]
    }
   ],
   "source": [
    "# Inspect the length of texts\n",
    "print(np.percentile(lengthText.counts, 70))\n",
    "print(np.percentile(lengthText.counts, 90))\n",
    "print(np.percentile(lengthText.counts, 95))\n",
    "print(np.percentile(lengthText.counts, 99))\n",
    "\n",
    "# Inspect the length of summaries\n",
    "print(np.percentile(lengthSummaries.counts, 70))\n",
    "print(np.percentile(lengthSummaries.counts, 90))\n",
    "print(np.percentile(lengthSummaries.counts, 95))\n",
    "print(np.percentile(lengthSummaries.counts, 99.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47962\n",
      "47962\n"
     ]
    }
   ],
   "source": [
    "maximumTextLength = 464\n",
    "maximumSummaryLength = 49\n",
    "minimumTextLength = 2\n",
    "minimumSummaryLength = 2\n",
    "unknownsInSummaryLimit = 4\n",
    "unknownsInTextLimit = 10\n",
    "        \n",
    "summariesAndTextSequence = list(zip(summariesToNumberSequence, textToNumberSequence))\n",
    "sortedSummaries, sortedText = Utils.applyFilterAndSort(summariesAndTextSequence, {\n",
    "    'maximumTextLength': maximumTextLength,\n",
    "    'maximumSummaryLength': maximumSummaryLength,\n",
    "    'minimumTextLength': minimumTextLength,\n",
    "    'minimumSummaryLength': minimumSummaryLength,\n",
    "    'unknownsInSummaryLimit': unknownsInSummaryLimit,\n",
    "    'unknownsInTextLimit': unknownsInTextLimit,\n",
    "    'unknownTokenNumberRepresentation': embedding.specialTokens['UNKNOWN']\n",
    "})\n",
    "\n",
    "# Compare lengths to ensure they match\n",
    "print(len(sortedSummaries))\n",
    "print(len(sortedText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.pickle(\"data/sorted_summaries.pkl\",sortedSummaries)\n",
    "Utils.pickle(\"data/sorted_text.pkl\",sortedText)\n",
    "Utils.pickle(\"data/embeddings_matrix.pkl\",embeddingsMatrix)\n",
    "Utils.pickle(\"data/word_to_int.pkl\",wordToIntDict)\n",
    "Utils.pickle(\"data/int_to_word.pkl\",intToWordDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedSummaries = Utils.unPickle(\"data/sorted_summaries.pkl\")\n",
    "sortedText = Utils.unPickle(\"data/sorted_text.pkl\")\n",
    "embeddingsMatrix = Utils.unPickle(\"data/embeddings_matrix.pkl\")\n",
    "wordToIntDict = Utils.unPickle(\"data/word_to_int.pkl\")\n",
    "intToWordDict = Utils.unPickle(\"data/int_to_word.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel:\n",
    "    \"\"\"\n",
    "    The implementation for Sequence to sequence modelling\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"The constructor. Your subclass's constructor can add\n",
    "        other arguments.\"\"\"\n",
    "        \n",
    "    def createModelInputsPlaceholders(self):\n",
    "        inputData = tf.placeholder(tf.int32, [None, None], name='inputData')\n",
    "        targetData = tf.placeholder(tf.int32, [None, None], name='targetData')\n",
    "        learningRate = tf.placeholder(tf.float32, name='learningRate')\n",
    "        dropoutRate = tf.placeholder(tf.float32, name='dropoutRate')\n",
    "        inputSummaryLengths = tf.placeholder(tf.int32, (None,), name='inputSummaryLengths')\n",
    "        maximumSummaryLength = tf.reduce_max(inputSummaryLengths, name='maximumSummaryLength')\n",
    "        inputTextLengths = tf.placeholder(tf.int32, (None,), name='inputTextLengths')\n",
    "\n",
    "        return inputData, targetData, learningRate, dropoutRate, inputSummaryLengths, maximumSummaryLength, inputTextLengths\n",
    "        \n",
    "    def createLSTMCell(self, rnnPerCellUnitsCount, requireDropoutLayer = False, dropoutRate = 0.95):\n",
    "        # Creating the RNN cell\n",
    "        cell = tf.contrib.rnn.LSTMCell(rnnPerCellUnitsCount,\n",
    "                                              initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "        \n",
    "        # Attaching a dropout layer for the cell if required\n",
    "        if requireDropoutLayer:\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob = dropoutRate)\n",
    "        return cell\n",
    "    \n",
    "    '''def createBasicLSTMCell(self, rnnPerCellUnitsCount, requireDropoutLayer = False, dropoutRate = 0.95):\n",
    "        # Creating the RNN cell\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(rnnPerCellUnitsCount)\n",
    "        # Attaching a dropout layer for the cell if required\n",
    "        if requireDropoutLayer:\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob = dropoutRate)\n",
    "            print('Finished createBasicLSTMCell ==> DropoutWrapper')\n",
    "        return cell'''\n",
    "    \n",
    "    def doEncoding(self, rnnPerCellUnitsCount, inputTextLengths, rnnCellsCount, embeddedEncoderInput, dropoutRate):\n",
    "        \"\"\"\n",
    "        This is the implementation of an encoding process.\n",
    "        \"\"\"\n",
    "        for rnnCellIndex in range(rnnCellsCount):\n",
    "            with tf.variable_scope('encoder_{}'.format(rnnCellIndex)):\n",
    "                # Creating the forward RNN cell for the Bi-directional RNN\n",
    "                forwardCell = self.createLSTMCell(rnnPerCellUnitsCount, \n",
    "                                             requireDropoutLayer = True, \n",
    "                                             dropoutRate = dropoutRate)\n",
    "                \n",
    "                # Creating the backward RNN cell for the Bi-directional RNN\n",
    "                backwardCell = self.createLSTMCell(rnnPerCellUnitsCount, \n",
    "                                             requireDropoutLayer = True, \n",
    "                                             dropoutRate = dropoutRate)\n",
    "                \n",
    "                # Connecting the forward and backward cells to create a Bi-directional RNN\n",
    "                encoderOutput, encoderStates = tf.nn.bidirectional_dynamic_rnn(forwardCell, \n",
    "                                                                    backwardCell, \n",
    "                                                                    embeddedEncoderInput,\n",
    "                                                                    inputTextLengths,\n",
    "                                                                    dtype=tf.float32)\n",
    "                encoderOutput = tf.concat(encoderOutput, 2)\n",
    "                # The current layer's output is being fed into next layer's input\n",
    "                embeddedEncoderInput = encoderOutput\n",
    "        return encoderOutput, encoderStates\n",
    "    \n",
    "    def processDecoderInput(self, targetData, wordToIntDict, batchSize, startToken):\n",
    "        \"\"\"\n",
    "        Remove the last word id from each batch and concatenate the id of the STARTOFSEQUENCE to the \n",
    "        begining of each batch.\n",
    "        \"\"\"\n",
    "        ending = tf.strided_slice(targetData, [0, 0], [batchSize, -1], [1, 1])\n",
    "        decoderInput = tf.concat([tf.fill([batchSize, 1], wordToIntDict[startToken]), ending], 1)\n",
    "        return decoderInput\n",
    "        \n",
    "    def processTrainingLayerForDecoder(self, embeddedDecoderInput, inputSummaryLengths, decoderCell,\n",
    "                                      outputLayer, totalWordsCountInVocab, maximumSummaryLength,\n",
    "                                      batchSize):\n",
    "        \"\"\"\n",
    "        This is the implementation for a Training decoding layer.\n",
    "        \"\"\"\n",
    "        trainingHelper = tf.contrib.seq2seq.TrainingHelper(inputs = embeddedDecoderInput,\n",
    "                                                        sequence_length = inputSummaryLengths,\n",
    "                                                        time_major = False)\n",
    "        \n",
    "        trainingDecoder = tf.contrib.seq2seq.BasicDecoder(cell = decoderCell,\n",
    "                                                       helper = trainingHelper,\n",
    "                                                       initial_state = decoderCell.zero_state(\n",
    "                                                           dtype=tf.float32, batch_size=batchSize),\n",
    "                                                       output_layer = outputLayer)\n",
    "        \n",
    "        trainingLogits = tf.contrib.seq2seq.dynamic_decode(trainingDecoder,\n",
    "                                                           output_time_major = False,\n",
    "                                                           impute_finished = True,\n",
    "                                                           maximum_iterations = maximumSummaryLength)\n",
    "        return trainingLogits\n",
    "        \n",
    "    def processInferenceLayerForDecoder(self, embeddingsMatrix, startOfSequenceToken, endOfSequenceToken,\n",
    "                                       decoderCell, outputLayer, maximumSummaryLength, batchSize):\n",
    "        \"\"\"\n",
    "        This is the implementation for an Inference decoding layer.\n",
    "        \"\"\"\n",
    "        startTokens = tf.tile(tf.constant([startOfSequenceToken], dtype=tf.int32), \n",
    "                              [batchSize], \n",
    "                              name='start_tokens')\n",
    "        \n",
    "        inferenceHelper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embeddingsMatrix,\n",
    "                                                                   startTokens,\n",
    "                                                                   endOfSequenceToken)\n",
    "        \n",
    "        inferenceDecoder = tf.contrib.seq2seq.BasicDecoder(decoderCell,\n",
    "                                                        inferenceHelper,\n",
    "                                                        decoderCell.zero_state(\n",
    "                                                            dtype=tf.float32, batch_size=batchSize),\n",
    "                                                        outputLayer)\n",
    "        \n",
    "        inferenceLogits = tf.contrib.seq2seq.dynamic_decode(inferenceDecoder,\n",
    "                                                            output_time_major=False,\n",
    "                                                            impute_finished=True,\n",
    "                                                            maximum_iterations=maximumSummaryLength)\n",
    "        \n",
    "        return inferenceLogits\n",
    "    \n",
    "    def doDecoding(self, embeddedDecoderInput, embeddingsMatrix, encoderOutput, encoderStates,\n",
    "                   totalWordsCountInVocab, inputTextLengths, inputSummaryLengths, maximumSummaryLength, \n",
    "                   rnnPerCellUnitsCount, wordToIntDict, dropoutRate, batchSize, rnnCellsCount, \n",
    "                   enableAttention = True):\n",
    "        # Creating the RNN cell for the decoder\n",
    "        decoderCell = tf.contrib.rnn.MultiRNNCell([self.createLSTMCell(rnnPerCellUnitsCount, requireDropoutLayer = True, dropoutRate = dropoutRate) for _ in range(rnnCellsCount)])\n",
    "\n",
    "        # If an additional Attention layer needs to be applied\n",
    "        if enableAttention:\n",
    "            attentionMechanism = tf.contrib.seq2seq.BahdanauAttention(rnnPerCellUnitsCount,\n",
    "                                                     encoderOutput,\n",
    "                                                     inputTextLengths,\n",
    "                                                     normalize = False,\n",
    "                                                     name = 'BahdanauAttention')\n",
    "            decoderCell = tf.contrib.seq2seq.AttentionWrapper(decoderCell, attentionMechanism, rnnPerCellUnitsCount)\n",
    "            \n",
    "        outputLayer = Dense(totalWordsCountInVocab, \n",
    "                            kernel_initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
    "        with tf.variable_scope(\"decode\"):\n",
    "            trainingLogits = self.processTrainingLayerForDecoder(embeddedDecoderInput,\n",
    "                                                            inputSummaryLengths,\n",
    "                                                            decoderCell,\n",
    "                                                            outputLayer,\n",
    "                                                            totalWordsCountInVocab,\n",
    "                                                            maximumSummaryLength,\n",
    "                                                            batchSize)\n",
    "        with tf.variable_scope(\"decode\", reuse=True):\n",
    "            inferenceLogits = self.processInferenceLayerForDecoder(embeddingsMatrix,\n",
    "                                                               wordToIntDict[embedding.specialTokens['STARTOFSEQUENCE']],\n",
    "                                                               wordToIntDict[embedding.specialTokens['ENDOFSEQUENCE']],\n",
    "                                                               decoderCell,\n",
    "                                                               outputLayer,\n",
    "                                                               maximumSummaryLength,\n",
    "                                                               batchSize)\n",
    "        return trainingLogits, inferenceLogits\n",
    "    \n",
    "    def process(self, inputData, targetData, dropoutRate, inputTextLengths, inputSummaryLengths, \n",
    "                maximumSummaryLength, totalWordsCountInVocab, rnnPerCellUnitsCount, \n",
    "                rnnCellsCount, wordToIntDict, batchSize, embeddingsMatrix):\n",
    "        \n",
    "        # Performing parallel lookups of inputData on the embeddingMatrix\n",
    "        embeddedEncoderInput = tf.nn.embedding_lookup(embeddingsMatrix, inputData)\n",
    "        \n",
    "        # Performing the encoding\n",
    "        encoderOutput, encoderStates = self.doEncoding(rnnPerCellUnitsCount,\n",
    "                                                       inputTextLengths,\n",
    "                                                       rnnCellsCount,\n",
    "                                                       embeddedEncoderInput,\n",
    "                                                       dropoutRate)\n",
    "        \n",
    "        # Process the decoder input before passing to decoding layer\n",
    "        decoderInput = self.processDecoderInput(targetData, \n",
    "                                           wordToIntDict, \n",
    "                                           batchSize, \n",
    "                                           embedding.specialTokens['STARTOFSEQUENCE'])\n",
    "        \n",
    "        # Performing parallel lookups of decoder input on the embeddingMatrix\n",
    "        embeddedDecoderInput = tf.nn.embedding_lookup(embeddingsMatrix, decoderInput)\n",
    "        \n",
    "        # Performing the encoding\n",
    "        trainingLogits, inferenceLogits = self.doDecoding(embeddedDecoderInput,\n",
    "                                                     embeddingsMatrix,\n",
    "                                                     encoderOutput,\n",
    "                                                     encoderStates,\n",
    "                                                     totalWordsCountInVocab,\n",
    "                                                     inputTextLengths,\n",
    "                                                     inputSummaryLengths,\n",
    "                                                     maximumSummaryLength,\n",
    "                                                     rnnPerCellUnitsCount,\n",
    "                                                     wordToIntDict,\n",
    "                                                     dropoutRate,\n",
    "                                                     batchSize,\n",
    "                                                     rnnCellsCount)\n",
    "        \n",
    "        return trainingLogits, inferenceLogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchDataGenerator:\n",
    "    \"\"\"\n",
    "    A class which helps in the generation of batches of data\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def generateBatches(summaries, texts, batchSize, paddingToken):\n",
    "        def padBatchContents(contents, paddingToken):\n",
    "            maxContentLength = max([len(content) for content in contents])\n",
    "            return [content + [paddingToken] * (maxContentLength - len(content)) for content in contents]\n",
    "        possibleBatchCount = len(texts)//batchSize\n",
    "        for batchIndex in range(0, possibleBatchCount):\n",
    "            batchStartPoint = batchIndex * batchSize\n",
    "            summariesBatch = summaries[batchStartPoint: batchStartPoint + batchSize]\n",
    "            textBatch = texts[batchStartPoint: batchStartPoint + batchSize]\n",
    "            paddedSummariesBatch = np.array(padBatchContents(summariesBatch, paddingToken))\n",
    "            paddedTextBatch = np.array(padBatchContents(textBatch, paddingToken))\n",
    "            \n",
    "            # Need the lengths for the lengths parameters\n",
    "            paddedSummariesLength = []\n",
    "            for summary in paddedSummariesBatch:\n",
    "                paddedSummariesLength.append(len(summary))\n",
    "\n",
    "            paddedTextLength = []\n",
    "            for text in paddedTextBatch:\n",
    "                paddedTextLength.append(len(text))\n",
    "\n",
    "            yield paddedSummariesBatch, paddedTextBatch, paddedSummariesLength, paddedTextLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<PAD>' has id: 155834\n",
      "pad summaries batch samples:\n",
      "\r",
      " [[   195   3179   1094   4796 155305   8324   8703 155269   2069   3471\n",
      "    5749 155323 155351  17601   6472   3687 155272    119    695    322\n",
      "    4082 155341 155313   1084 155270   3337   5294  27755 155834 155834\n",
      "  155834 155834 155834 155834 155834 155834 155834 155834 155834]\n",
      " [ 19844  22845 155267   2674   1053    438  30564 155308 155269   4353\n",
      "   22084    322   6146   4350 155305  12480  26407 155267  37460 155834\n",
      "  155834 155834 155834 155834 155834 155834 155834 155834 155834 155834\n",
      "  155834 155834 155834 155834 155834 155834 155834 155834 155834]\n",
      " [155269    251 155282    674   8423 155278   1293 155269    535 155295\n",
      "  155289   6783 155277 155269   7906   1010 155834 155834 155834 155834\n",
      "  155834 155834 155834 155834 155834 155834 155834 155834 155834 155834\n",
      "  155834 155834 155834 155834 155834 155834 155834 155834 155834]\n",
      " [    31 155267   9595   1341    812 155270   7346    221 155293  12904\n",
      "  155289   2728    433  12904   4673 155277  18013 155277    796   5596\n",
      "  155357 155350 155324 155274  15612    986    875   2633  15533  24628\n",
      "  155317 155283  12905 155305   2738    433   1421 155834 155834]\n",
      " [  3213 155361 155277   1068  18339 155308   1127   1532   3778   2478\n",
      "      25    399 155272    370 155270   2695   2226  20770 155267    264\n",
      "    1084 155286   1532   1583 155289   6014   2064 155270   2004   1095\n",
      "    8084 155289 155291   9645 155305  35862 155289    822   5641]]\n"
     ]
    }
   ],
   "source": [
    "paddingToken = wordToIntDict[embedding.specialTokens['PADDING']]\n",
    "print(\"'<PAD>' has id: {}\".format(paddingToken))\n",
    "sortedSummariesSamples = sortedSummaries[7:50]\n",
    "sortedTextSamples = sortedText[7:50]\n",
    "pad_summaries_batch_samples, pad_texts_batch_samples, pad_summaries_lengths_samples, pad_texts_lengths_samples = next(BatchDataGenerator.generateBatches(sortedSummariesSamples, sortedTextSamples, 5, paddingToken))\n",
    "print(\"pad summaries batch samples:\\n\\r {}\".format(pad_summaries_batch_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Hyperparameters\n",
    "epochs = 100\n",
    "batchSize = 50\n",
    "rnnPerCellUnitsCount = 256\n",
    "rnnCellsCount = 2\n",
    "learningRate = 0.005\n",
    "dropoutRate = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph is built.\n",
      "./graph\n"
     ]
    }
   ],
   "source": [
    "seq2seqModel = Seq2SeqModel()\n",
    "# Build the graph\n",
    "train_graph = tf.Graph()\n",
    "# Set the graph to default to ensure that it is ready for training\n",
    "with train_graph.as_default():\n",
    "    \n",
    "    # Load the model inputs    \n",
    "    input_data, targets, lr, dropout_rate, summary_length, max_summary_length, text_length = seq2seqModel.createModelInputsPlaceholders()\n",
    "\n",
    "    # Create the training and inference logits\n",
    "    trainingLogits, inferenceLogits = seq2seqModel.process(tf.reverse(input_data, [-1]),\n",
    "                                                      targets, \n",
    "                                                      dropout_rate,   \n",
    "                                                      text_length,\n",
    "                                                      summary_length,\n",
    "                                                      max_summary_length,\n",
    "                                                      len(wordToIntDict)+1,\n",
    "                                                      rnnPerCellUnitsCount, \n",
    "                                                      rnnCellsCount, \n",
    "                                                      wordToIntDict,\n",
    "                                                      batchSize,\n",
    "                                                      embeddingsMatrix)\n",
    "    \n",
    "    # Create tensors for the training logits and inference logits\n",
    "    trainingLogits = tf.identity(trainingLogits[0].rnn_output, 'logits')\n",
    "    inferenceLogits = tf.identity(inferenceLogits[0].sample_id, name='predictions')\n",
    "    \n",
    "    # Create the weights for sequence_loss, the sould be all True across since each batch is padded\n",
    "    masks = tf.sequence_mask(summary_length, max_summary_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            trainingLogits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learningRate)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n",
    "print(\"Graph is built.\")\n",
    "graph_location = \"./graph\"\n",
    "print(graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(train_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47962\n",
      "3000\n",
      "The shortest text length: 44\n",
      "The longest text length: 434\n"
     ]
    }
   ],
   "source": [
    "# Subset the data for training\n",
    "start = 150\n",
    "end = start + 45000\n",
    "print(len(sortedSummaries))\n",
    "sampledSortedSummaries = sortedSummaries[start:end:15]\n",
    "sampledSortedText = sortedText[start:end:15]\n",
    "print(len(sampledSortedSummaries))\n",
    "print(\"The shortest text length:\", len(sampledSortedText[0]))\n",
    "print(\"The longest text length:\",len(sampledSortedText[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100 Batch   10/60 - Loss: 10.311, Seconds: 216.82\n",
      "Epoch   1/100 Batch   20/60 - Loss:  6.616, Seconds: 243.38\n",
      "Epoch   1/100 Batch   30/60 - Loss:  6.598, Seconds: 281.27\n",
      "Epoch   1/100 Batch   40/60 - Loss:  6.622, Seconds: 313.89\n",
      "Epoch   1/100 Batch   50/60 - Loss:  6.453, Seconds: 336.14\n",
      "Average loss for this update: 7.32\n",
      "New Record!\n",
      "Epoch   1/100 Batch   60/60 - Loss:  6.670, Seconds: 405.37\n",
      "Epoch   2/100 Batch   10/60 - Loss:  5.338, Seconds: 223.33\n",
      "Epoch   2/100 Batch   20/60 - Loss:  5.745, Seconds: 251.36\n",
      "Epoch   2/100 Batch   30/60 - Loss:  6.088, Seconds: 273.84\n",
      "Epoch   2/100 Batch   40/60 - Loss:  6.194, Seconds: 331.02\n",
      "Epoch   2/100 Batch   50/60 - Loss:  6.130, Seconds: 344.45\n",
      "Average loss for this update: 5.899\n",
      "New Record!\n",
      "Epoch   2/100 Batch   60/60 - Loss:  6.345, Seconds: 396.47\n",
      "Epoch   3/100 Batch   10/60 - Loss:  5.262, Seconds: 224.32\n",
      "Epoch   3/100 Batch   20/60 - Loss:  5.708, Seconds: 256.19\n",
      "Epoch   3/100 Batch   30/60 - Loss:  5.982, Seconds: 312.27\n",
      "Epoch   3/100 Batch   40/60 - Loss:  6.082, Seconds: 319.30\n",
      "Epoch   3/100 Batch   50/60 - Loss:  5.970, Seconds: 361.17\n",
      "Average loss for this update: 5.801\n",
      "New Record!\n",
      "Epoch   3/100 Batch   60/60 - Loss:  6.167, Seconds: 401.44\n",
      "Epoch   4/100 Batch   10/60 - Loss:  5.202, Seconds: 226.35\n",
      "Epoch   4/100 Batch   20/60 - Loss:  5.575, Seconds: 260.88\n",
      "Epoch   4/100 Batch   30/60 - Loss:  5.855, Seconds: 284.78\n",
      "Epoch   4/100 Batch   40/60 - Loss:  5.981, Seconds: 317.74\n",
      "Epoch   4/100 Batch   50/60 - Loss:  5.857, Seconds: 350.23\n",
      "Average loss for this update: 5.694\n",
      "New Record!\n",
      "Epoch   4/100 Batch   60/60 - Loss:  6.030, Seconds: 403.73\n",
      "Epoch   5/100 Batch   10/60 - Loss:  5.065, Seconds: 225.73\n",
      "Epoch   5/100 Batch   20/60 - Loss:  5.472, Seconds: 257.13\n",
      "Epoch   5/100 Batch   30/60 - Loss:  5.788, Seconds: 305.87\n",
      "Epoch   5/100 Batch   40/60 - Loss:  5.822, Seconds: 325.08\n",
      "Epoch   5/100 Batch   50/60 - Loss:  5.741, Seconds: 363.04\n",
      "Average loss for this update: 5.578\n",
      "New Record!\n",
      "Epoch   5/100 Batch   60/60 - Loss:  5.922, Seconds: 396.16\n",
      "Epoch   6/100 Batch   10/60 - Loss:  4.968, Seconds: 226.82\n",
      "Epoch   6/100 Batch   20/60 - Loss:  5.372, Seconds: 257.75\n",
      "Epoch   6/100 Batch   30/60 - Loss:  5.624, Seconds: 285.71\n",
      "Epoch   6/100 Batch   40/60 - Loss:  5.663, Seconds: 320.39\n",
      "Epoch   6/100 Batch   50/60 - Loss:  5.600, Seconds: 352.57\n",
      "Average loss for this update: 5.445\n",
      "New Record!\n",
      "Epoch   6/100 Batch   60/60 - Loss:  5.768, Seconds: 406.47\n",
      "Epoch   7/100 Batch   10/60 - Loss:  4.847, Seconds: 226.82\n",
      "Epoch   7/100 Batch   20/60 - Loss:  5.215, Seconds: 259.63\n",
      "Epoch   7/100 Batch   30/60 - Loss:  5.466, Seconds: 293.68\n",
      "Epoch   7/100 Batch   40/60 - Loss:  5.509, Seconds: 335.39\n",
      "Epoch   7/100 Batch   50/60 - Loss:  5.472, Seconds: 359.45\n",
      "Average loss for this update: 5.302\n",
      "New Record!\n",
      "Epoch   7/100 Batch   60/60 - Loss:  5.612, Seconds: 435.27\n",
      "Epoch   8/100 Batch   10/60 - Loss:  4.711, Seconds: 227.60\n",
      "Epoch   8/100 Batch   20/60 - Loss:  5.075, Seconds: 260.41\n",
      "Epoch   8/100 Batch   30/60 - Loss:  5.319, Seconds: 281.03\n",
      "Epoch   8/100 Batch   40/60 - Loss:  5.368, Seconds: 324.77\n",
      "Epoch   8/100 Batch   50/60 - Loss:  5.311, Seconds: 359.60\n",
      "Average loss for this update: 5.157\n",
      "New Record!\n",
      "Epoch   8/100 Batch   60/60 - Loss:  5.479, Seconds: 419.90\n",
      "Epoch   9/100 Batch   10/60 - Loss:  4.572, Seconds: 224.79\n",
      "Epoch   9/100 Batch   20/60 - Loss:  4.937, Seconds: 258.53\n",
      "Epoch   9/100 Batch   30/60 - Loss:  5.180, Seconds: 298.05\n",
      "Epoch   9/100 Batch   40/60 - Loss:  5.170, Seconds: 326.49\n",
      "Epoch   9/100 Batch   50/60 - Loss:  5.143, Seconds: 361.17\n",
      "Average loss for this update: 5.0\n",
      "New Record!\n",
      "Epoch   9/100 Batch   60/60 - Loss:  5.298, Seconds: 412.40\n",
      "Epoch  10/100 Batch   10/60 - Loss:  4.416, Seconds: 226.67\n",
      "Epoch  10/100 Batch   20/60 - Loss:  4.795, Seconds: 255.25\n",
      "Epoch  10/100 Batch   30/60 - Loss:  5.007, Seconds: 302.90\n",
      "Epoch  10/100 Batch   40/60 - Loss:  5.014, Seconds: 326.87\n",
      "Epoch  10/100 Batch   50/60 - Loss:  4.972, Seconds: 356.48\n",
      "Average loss for this update: 4.841\n",
      "New Record!\n",
      "Epoch  10/100 Batch   60/60 - Loss:  5.136, Seconds: 419.90\n",
      "Epoch  11/100 Batch   10/60 - Loss:  4.299, Seconds: 228.07\n",
      "Epoch  11/100 Batch   20/60 - Loss:  4.648, Seconds: 254.47\n",
      "Epoch  11/100 Batch   30/60 - Loss:  4.857, Seconds: 295.24\n",
      "Epoch  11/100 Batch   40/60 - Loss:  4.862, Seconds: 338.23\n",
      "Epoch  11/100 Batch   50/60 - Loss:  4.829, Seconds: 363.66\n",
      "Average loss for this update: 4.699\n",
      "New Record!\n",
      "Epoch  11/100 Batch   60/60 - Loss:  5.002, Seconds: 409.75\n",
      "Epoch  12/100 Batch   10/60 - Loss:  4.166, Seconds: 228.44\n",
      "Epoch  12/100 Batch   20/60 - Loss:  4.520, Seconds: 263.53\n",
      "Epoch  12/100 Batch   30/60 - Loss:  4.709, Seconds: 298.37\n",
      "Epoch  12/100 Batch   40/60 - Loss:  4.737, Seconds: 327.74\n",
      "Epoch  12/100 Batch   50/60 - Loss:  4.676, Seconds: 362.72\n",
      "Average loss for this update: 4.561\n",
      "New Record!\n",
      "Epoch  12/100 Batch   60/60 - Loss:  4.821, Seconds: 419.59\n",
      "Epoch  13/100 Batch   10/60 - Loss:  4.048, Seconds: 226.98\n",
      "Epoch  13/100 Batch   20/60 - Loss:  4.355, Seconds: 257.75\n",
      "Epoch  13/100 Batch   30/60 - Loss:  4.565, Seconds: 295.56\n",
      "Epoch  13/100 Batch   40/60 - Loss:  4.598, Seconds: 316.64\n",
      "Epoch  13/100 Batch   50/60 - Loss:  4.517, Seconds: 361.80\n",
      "Average loss for this update: 4.417\n",
      "New Record!\n",
      "Epoch  13/100 Batch   60/60 - Loss:  4.676, Seconds: 408.35\n",
      "Epoch  14/100 Batch   10/60 - Loss:  3.914, Seconds: 226.51\n",
      "Epoch  14/100 Batch   20/60 - Loss:  4.208, Seconds: 257.13\n",
      "Epoch  14/100 Batch   30/60 - Loss:  4.398, Seconds: 299.30\n",
      "Epoch  14/100 Batch   40/60 - Loss:  4.427, Seconds: 324.88\n",
      "Epoch  14/100 Batch   50/60 - Loss:  4.347, Seconds: 356.63\n",
      "Average loss for this update: 4.259\n",
      "New Record!\n",
      "Epoch  14/100 Batch   60/60 - Loss:  4.484, Seconds: 410.37\n",
      "Epoch  15/100 Batch   10/60 - Loss:  3.788, Seconds: 229.48\n",
      "Epoch  15/100 Batch   20/60 - Loss:  4.044, Seconds: 259.31\n",
      "Epoch  15/100 Batch   30/60 - Loss:  4.230, Seconds: 290.09\n",
      "Epoch  15/100 Batch   40/60 - Loss:  4.240, Seconds: 339.92\n",
      "Epoch  15/100 Batch   50/60 - Loss:  4.174, Seconds: 367.26\n",
      "Average loss for this update: 4.095\n",
      "New Record!\n",
      "Epoch  15/100 Batch   60/60 - Loss:  4.284, Seconds: 416.31\n",
      "Epoch  16/100 Batch   10/60 - Loss:  3.617, Seconds: 227.13\n",
      "Epoch  16/100 Batch   20/60 - Loss:  3.849, Seconds: 258.22\n",
      "Epoch  16/100 Batch   30/60 - Loss:  4.033, Seconds: 297.05\n",
      "Epoch  16/100 Batch   40/60 - Loss:  4.057, Seconds: 328.36\n",
      "Epoch  16/100 Batch   50/60 - Loss:  3.995, Seconds: 373.19\n",
      "Average loss for this update: 3.91\n",
      "New Record!\n",
      "Epoch  16/100 Batch   60/60 - Loss:  4.109, Seconds: 415.21\n",
      "Epoch  17/100 Batch   10/60 - Loss:  3.439, Seconds: 226.51\n",
      "Epoch  17/100 Batch   20/60 - Loss:  3.673, Seconds: 265.09\n",
      "Epoch  17/100 Batch   30/60 - Loss:  3.849, Seconds: 287.90\n",
      "Epoch  17/100 Batch   40/60 - Loss:  3.854, Seconds: 338.20\n",
      "Epoch  17/100 Batch   50/60 - Loss:  3.833, Seconds: 364.45\n",
      "Average loss for this update: 3.73\n",
      "New Record!\n",
      "Epoch  17/100 Batch   60/60 - Loss:  3.909, Seconds: 433.80\n",
      "Epoch  18/100 Batch   10/60 - Loss:  3.273, Seconds: 227.76\n",
      "Epoch  18/100 Batch   20/60 - Loss:  3.501, Seconds: 265.09\n",
      "Epoch  18/100 Batch   30/60 - Loss:  3.696, Seconds: 304.62\n",
      "Epoch  18/100 Batch   40/60 - Loss:  3.683, Seconds: 350.07\n",
      "Epoch  18/100 Batch   50/60 - Loss:  3.651, Seconds: 358.67\n",
      "Average loss for this update: 3.561\n",
      "New Record!\n",
      "Epoch  18/100 Batch   60/60 - Loss:  3.727, Seconds: 420.21\n",
      "Epoch  19/100 Batch   10/60 - Loss:  3.126, Seconds: 227.13\n",
      "Epoch  19/100 Batch   20/60 - Loss:  3.352, Seconds: 262.44\n",
      "Epoch  19/100 Batch   30/60 - Loss:  3.509, Seconds: 288.37\n",
      "Epoch  19/100 Batch   40/60 - Loss:  3.508, Seconds: 326.17\n",
      "Epoch  19/100 Batch   50/60 - Loss:  3.486, Seconds: 363.82\n",
      "Average loss for this update: 3.396\n",
      "New Record!\n",
      "Epoch  19/100 Batch   60/60 - Loss:  3.564, Seconds: 414.58\n",
      "Epoch  20/100 Batch   10/60 - Loss:  2.972, Seconds: 228.07\n",
      "Epoch  20/100 Batch   20/60 - Loss:  3.178, Seconds: 262.29\n",
      "Epoch  20/100 Batch   30/60 - Loss:  3.378, Seconds: 304.62\n",
      "Epoch  20/100 Batch   40/60 - Loss:  3.369, Seconds: 339.30\n",
      "Epoch  20/100 Batch   50/60 - Loss:  3.334, Seconds: 363.79\n",
      "Average loss for this update: 3.246\n",
      "New Record!\n",
      "Epoch  20/100 Batch   60/60 - Loss:  3.396, Seconds: 423.34\n",
      "Epoch  21/100 Batch   10/60 - Loss:  2.842, Seconds: 230.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  21/100 Batch   20/60 - Loss:  3.026, Seconds: 288.21\n",
      "Epoch  21/100 Batch   30/60 - Loss:  3.204, Seconds: 284.62\n",
      "Epoch  21/100 Batch   40/60 - Loss:  3.192, Seconds: 354.49\n",
      "Epoch  21/100 Batch   50/60 - Loss:  3.169, Seconds: 365.54\n",
      "Average loss for this update: 3.087\n",
      "New Record!\n",
      "Epoch  21/100 Batch   60/60 - Loss:  3.242, Seconds: 426.93\n",
      "Epoch  22/100 Batch   10/60 - Loss:  2.675, Seconds: 232.91\n",
      "Epoch  22/100 Batch   20/60 - Loss:  2.888, Seconds: 259.28\n",
      "Epoch  22/100 Batch   30/60 - Loss:  3.069, Seconds: 308.21\n",
      "Epoch  22/100 Batch   40/60 - Loss:  3.050, Seconds: 323.30\n",
      "Epoch  22/100 Batch   50/60 - Loss:  3.033, Seconds: 371.63\n",
      "Average loss for this update: 2.943\n",
      "New Record!\n",
      "Epoch  22/100 Batch   60/60 - Loss:  3.097, Seconds: 426.93\n",
      "Epoch  23/100 Batch   10/60 - Loss:  2.570, Seconds: 230.41\n",
      "Epoch  23/100 Batch   20/60 - Loss:  2.776, Seconds: 285.40\n",
      "Epoch  23/100 Batch   30/60 - Loss:  2.926, Seconds: 306.33\n",
      "Epoch  23/100 Batch   40/60 - Loss:  2.910, Seconds: 344.77\n",
      "Epoch  23/100 Batch   50/60 - Loss:  2.911, Seconds: 382.72\n",
      "Average loss for this update: 2.818\n",
      "New Record!\n",
      "Epoch  23/100 Batch   60/60 - Loss:  2.983, Seconds: 422.71\n",
      "Epoch  24/100 Batch   10/60 - Loss:  2.476, Seconds: 227.92\n",
      "Epoch  24/100 Batch   20/60 - Loss:  2.654, Seconds: 259.78\n",
      "Epoch  24/100 Batch   30/60 - Loss:  2.804, Seconds: 306.02\n",
      "Epoch  24/100 Batch   40/60 - Loss:  2.781, Seconds: 344.03\n",
      "Epoch  24/100 Batch   50/60 - Loss:  2.778, Seconds: 367.10\n",
      "Average loss for this update: 2.699\n",
      "New Record!\n",
      "Epoch  24/100 Batch   60/60 - Loss:  2.803, Seconds: 423.65\n",
      "Epoch  25/100 Batch   10/60 - Loss:  2.354, Seconds: 231.20\n",
      "Epoch  25/100 Batch   20/60 - Loss:  2.529, Seconds: 284.31\n",
      "Epoch  25/100 Batch   30/60 - Loss:  2.667, Seconds: 288.24\n",
      "Epoch  25/100 Batch   40/60 - Loss:  2.624, Seconds: 313.68\n",
      "Epoch  25/100 Batch   50/60 - Loss:  2.655, Seconds: 384.28\n",
      "Average loss for this update: 2.566\n",
      "New Record!\n",
      "Epoch  25/100 Batch   60/60 - Loss:  2.691, Seconds: 433.49\n",
      "Epoch  26/100 Batch   10/60 - Loss:  2.237, Seconds: 231.98\n",
      "Epoch  26/100 Batch   20/60 - Loss:  2.410, Seconds: 266.66\n",
      "Epoch  26/100 Batch   30/60 - Loss:  2.565, Seconds: 291.49\n",
      "Epoch  26/100 Batch   40/60 - Loss:  2.502, Seconds: 340.39\n",
      "Epoch  26/100 Batch   50/60 - Loss:  2.515, Seconds: 368.04\n",
      "Average loss for this update: 2.446\n",
      "New Record!\n",
      "Epoch  26/100 Batch   60/60 - Loss:  2.567, Seconds: 427.09\n",
      "Epoch  27/100 Batch   10/60 - Loss:  2.155, Seconds: 234.21\n",
      "Epoch  27/100 Batch   20/60 - Loss:  2.300, Seconds: 263.22\n",
      "Epoch  27/100 Batch   30/60 - Loss:  2.435, Seconds: 291.18\n",
      "Epoch  27/100 Batch   40/60 - Loss:  2.402, Seconds: 342.58\n",
      "Epoch  27/100 Batch   50/60 - Loss:  2.399, Seconds: 377.90\n",
      "Average loss for this update: 2.338\n",
      "New Record!\n",
      "Epoch  27/100 Batch   60/60 - Loss:  2.426, Seconds: 419.28\n",
      "Epoch  28/100 Batch   10/60 - Loss:  2.024, Seconds: 231.20\n",
      "Epoch  28/100 Batch   20/60 - Loss:  2.188, Seconds: 280.25\n",
      "Epoch  28/100 Batch   30/60 - Loss:  2.331, Seconds: 295.24\n",
      "Epoch  28/100 Batch   40/60 - Loss:  2.267, Seconds: 338.83\n",
      "Epoch  28/100 Batch   50/60 - Loss:  2.288, Seconds: 380.07\n",
      "Average loss for this update: 2.22\n",
      "New Record!\n",
      "Epoch  28/100 Batch   60/60 - Loss:  2.307, Seconds: 437.71\n",
      "Epoch  29/100 Batch   10/60 - Loss:  1.924, Seconds: 229.48\n",
      "Epoch  29/100 Batch   20/60 - Loss:  2.081, Seconds: 266.27\n",
      "Epoch  29/100 Batch   30/60 - Loss:  2.219, Seconds: 306.18\n",
      "Epoch  29/100 Batch   40/60 - Loss:  2.170, Seconds: 332.42\n",
      "Epoch  29/100 Batch   50/60 - Loss:  2.189, Seconds: 376.94\n",
      "Average loss for this update: 2.116\n",
      "New Record!\n",
      "Epoch  29/100 Batch   60/60 - Loss:  2.185, Seconds: 425.99\n",
      "Epoch  30/100 Batch   10/60 - Loss:  1.846, Seconds: 229.32\n",
      "Epoch  30/100 Batch   20/60 - Loss:  1.999, Seconds: 268.37\n",
      "Epoch  30/100 Batch   30/60 - Loss:  2.113, Seconds: 300.16\n",
      "Epoch  30/100 Batch   40/60 - Loss:  2.064, Seconds: 331.64\n",
      "Epoch  30/100 Batch   50/60 - Loss:  2.108, Seconds: 375.22\n",
      "Average loss for this update: 2.026\n",
      "New Record!\n",
      "Epoch  30/100 Batch   60/60 - Loss:  2.111, Seconds: 425.92\n",
      "Epoch  31/100 Batch   10/60 - Loss:  1.748, Seconds: 231.20\n",
      "Epoch  31/100 Batch   20/60 - Loss:  1.902, Seconds: 269.16\n",
      "Epoch  31/100 Batch   30/60 - Loss:  2.032, Seconds: 303.13\n",
      "Epoch  31/100 Batch   40/60 - Loss:  2.002, Seconds: 331.48\n",
      "Epoch  31/100 Batch   50/60 - Loss:  2.007, Seconds: 382.79\n",
      "Average loss for this update: 1.938\n",
      "New Record!\n",
      "Epoch  31/100 Batch   60/60 - Loss:  2.055, Seconds: 428.18\n",
      "Epoch  32/100 Batch   10/60 - Loss:  1.692, Seconds: 232.60\n",
      "Epoch  32/100 Batch   20/60 - Loss:  1.825, Seconds: 265.49\n",
      "Epoch  32/100 Batch   30/60 - Loss:  1.953, Seconds: 311.02\n",
      "Epoch  32/100 Batch   40/60 - Loss:  1.925, Seconds: 340.15\n",
      "Epoch  32/100 Batch   50/60 - Loss:  1.924, Seconds: 370.85\n",
      "Average loss for this update: 1.864\n",
      "New Record!\n",
      "Epoch  32/100 Batch   60/60 - Loss:  1.975, Seconds: 421.93\n",
      "Epoch  33/100 Batch   10/60 - Loss:  1.628, Seconds: 231.66\n",
      "Epoch  33/100 Batch   20/60 - Loss:  1.769, Seconds: 263.84\n",
      "Epoch  33/100 Batch   30/60 - Loss:  1.862, Seconds: 290.24\n",
      "Epoch  33/100 Batch   40/60 - Loss:  1.826, Seconds: 327.58\n",
      "Epoch  33/100 Batch   50/60 - Loss:  1.839, Seconds: 373.51\n",
      "Average loss for this update: 1.785\n",
      "New Record!\n",
      "Epoch  33/100 Batch   60/60 - Loss:  1.864, Seconds: 426.15\n",
      "Epoch  34/100 Batch   10/60 - Loss:  1.546, Seconds: 231.98\n",
      "Epoch  34/100 Batch   20/60 - Loss:  1.718, Seconds: 264.00\n",
      "Epoch  34/100 Batch   30/60 - Loss:  1.793, Seconds: 300.71\n",
      "Epoch  34/100 Batch   40/60 - Loss:  1.783, Seconds: 318.68\n",
      "Epoch  34/100 Batch   50/60 - Loss:  1.785, Seconds: 388.81\n",
      "Average loss for this update: 1.725\n",
      "New Record!\n",
      "Epoch  34/100 Batch   60/60 - Loss:  1.808, Seconds: 434.74\n",
      "Epoch  35/100 Batch   10/60 - Loss:  1.495, Seconds: 231.35\n",
      "Epoch  35/100 Batch   20/60 - Loss:  1.638, Seconds: 265.41\n",
      "Epoch  35/100 Batch   30/60 - Loss:  1.731, Seconds: 296.02\n",
      "Epoch  35/100 Batch   40/60 - Loss:  1.703, Seconds: 344.45\n",
      "Epoch  35/100 Batch   50/60 - Loss:  1.712, Seconds: 387.56\n",
      "Average loss for this update: 1.656\n",
      "New Record!\n",
      "Epoch  35/100 Batch   60/60 - Loss:  1.743, Seconds: 427.71\n",
      "Epoch  36/100 Batch   10/60 - Loss:  1.443, Seconds: 231.04\n",
      "Epoch  36/100 Batch   20/60 - Loss:  1.564, Seconds: 273.22\n",
      "Epoch  36/100 Batch   30/60 - Loss:  1.660, Seconds: 296.81\n",
      "Epoch  36/100 Batch   40/60 - Loss:  1.637, Seconds: 349.45\n",
      "Epoch  36/100 Batch   50/60 - Loss:  1.642, Seconds: 380.23\n",
      "Average loss for this update: 1.589\n",
      "New Record!\n",
      "Epoch  36/100 Batch   60/60 - Loss:  1.670, Seconds: 432.55\n",
      "Epoch  37/100 Batch   10/60 - Loss:  1.378, Seconds: 229.95\n",
      "Epoch  37/100 Batch   20/60 - Loss:  1.492, Seconds: 291.03\n",
      "Epoch  37/100 Batch   30/60 - Loss:  1.583, Seconds: 293.68\n",
      "Epoch  37/100 Batch   40/60 - Loss:  1.547, Seconds: 327.74\n",
      "Epoch  37/100 Batch   50/60 - Loss:  1.570, Seconds: 377.23\n",
      "Average loss for this update: 1.514\n",
      "New Record!\n",
      "Epoch  37/100 Batch   60/60 - Loss:  1.601, Seconds: 420.99\n",
      "Epoch  38/100 Batch   10/60 - Loss:  1.303, Seconds: 232.13\n",
      "Epoch  38/100 Batch   20/60 - Loss:  1.434, Seconds: 267.28\n",
      "Epoch  38/100 Batch   30/60 - Loss:  1.521, Seconds: 290.24\n",
      "Epoch  38/100 Batch   40/60 - Loss:  1.479, Seconds: 335.39\n",
      "Epoch  38/100 Batch   50/60 - Loss:  1.506, Seconds: 383.82\n",
      "Average loss for this update: 1.449\n",
      "New Record!\n",
      "Epoch  38/100 Batch   60/60 - Loss:  1.531, Seconds: 443.96\n",
      "Epoch  39/100 Batch   10/60 - Loss:  1.259, Seconds: 235.10\n",
      "Epoch  39/100 Batch   20/60 - Loss:  1.371, Seconds: 270.41\n",
      "Epoch  39/100 Batch   30/60 - Loss:  1.459, Seconds: 303.68\n",
      "Epoch  39/100 Batch   40/60 - Loss:  1.434, Seconds: 379.33\n",
      "Epoch  39/100 Batch   50/60 - Loss:  1.447, Seconds: 386.75\n",
      "Average loss for this update: 1.394\n",
      "New Record!\n",
      "Epoch  39/100 Batch   60/60 - Loss:  1.464, Seconds: 436.15\n",
      "Epoch  40/100 Batch   10/60 - Loss:  1.220, Seconds: 232.29\n",
      "Epoch  40/100 Batch   20/60 - Loss:  1.315, Seconds: 262.13\n",
      "Epoch  40/100 Batch   30/60 - Loss:  1.411, Seconds: 296.65\n",
      "Epoch  40/100 Batch   40/60 - Loss:  1.380, Seconds: 333.83\n",
      "Epoch  40/100 Batch   50/60 - Loss:  1.393, Seconds: 372.10\n",
      "Average loss for this update: 1.344\n",
      "New Record!\n",
      "Epoch  40/100 Batch   60/60 - Loss:  1.411, Seconds: 433.80\n",
      "Epoch  41/100 Batch   10/60 - Loss:  1.171, Seconds: 234.48\n",
      "Epoch  41/100 Batch   20/60 - Loss:  1.266, Seconds: 268.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  41/100 Batch   30/60 - Loss:  1.360, Seconds: 293.82\n",
      "Epoch  41/100 Batch   40/60 - Loss:  1.340, Seconds: 338.20\n",
      "Epoch  41/100 Batch   50/60 - Loss:  1.361, Seconds: 371.48\n",
      "Average loss for this update: 1.299\n",
      "New Record!\n",
      "Epoch  41/100 Batch   60/60 - Loss:  1.373, Seconds: 435.99\n",
      "Epoch  42/100 Batch   10/60 - Loss:  1.138, Seconds: 235.60\n",
      "Epoch  42/100 Batch   20/60 - Loss:  1.230, Seconds: 266.34\n",
      "Epoch  42/100 Batch   30/60 - Loss:  1.300, Seconds: 303.14\n",
      "Epoch  42/100 Batch   40/60 - Loss:  1.275, Seconds: 343.67\n",
      "Epoch  42/100 Batch   50/60 - Loss:  1.296, Seconds: 380.69\n",
      "Average loss for this update: 1.248\n",
      "New Record!\n",
      "Epoch  42/100 Batch   60/60 - Loss:  1.317, Seconds: 431.62\n",
      "Epoch  43/100 Batch   10/60 - Loss:  1.092, Seconds: 234.84\n",
      "Epoch  43/100 Batch   20/60 - Loss:  1.179, Seconds: 272.12\n",
      "Epoch  43/100 Batch   30/60 - Loss:  1.251, Seconds: 323.37\n",
      "Epoch  43/100 Batch   40/60 - Loss:  1.233, Seconds: 343.20\n",
      "Epoch  43/100 Batch   50/60 - Loss:  1.261, Seconds: 379.99\n",
      "Average loss for this update: 1.203\n",
      "New Record!\n",
      "Epoch  43/100 Batch   60/60 - Loss:  1.280, Seconds: 434.12\n",
      "Epoch  44/100 Batch   10/60 - Loss:  1.071, Seconds: 233.85\n",
      "Epoch  44/100 Batch   20/60 - Loss:  1.142, Seconds: 280.87\n",
      "Epoch  44/100 Batch   30/60 - Loss:  1.207, Seconds: 308.32\n",
      "Epoch  44/100 Batch   40/60 - Loss:  1.184, Seconds: 343.10\n",
      "Epoch  44/100 Batch   50/60 - Loss:  1.218, Seconds: 385.38\n",
      "Average loss for this update: 1.164\n",
      "New Record!\n",
      "Epoch  44/100 Batch   60/60 - Loss:  1.230, Seconds: 433.65\n",
      "Epoch  45/100 Batch   10/60 - Loss:  1.026, Seconds: 234.48\n",
      "Epoch  45/100 Batch   20/60 - Loss:  1.106, Seconds: 267.75\n",
      "Epoch  45/100 Batch   30/60 - Loss:  1.160, Seconds: 313.05\n",
      "Epoch  45/100 Batch   40/60 - Loss:  1.162, Seconds: 328.83\n",
      "Epoch  45/100 Batch   50/60 - Loss:  1.182, Seconds: 376.63\n",
      "Average loss for this update: 1.127\n",
      "New Record!\n",
      "Epoch  45/100 Batch   60/60 - Loss:  1.202, Seconds: 437.40\n",
      "Epoch  46/100 Batch   10/60 - Loss:  0.990, Seconds: 233.70\n",
      "Epoch  46/100 Batch   20/60 - Loss:  1.069, Seconds: 268.53\n",
      "Epoch  46/100 Batch   30/60 - Loss:  1.132, Seconds: 322.53\n",
      "Epoch  46/100 Batch   40/60 - Loss:  1.119, Seconds: 338.05\n",
      "Epoch  46/100 Batch   50/60 - Loss:  1.142, Seconds: 371.65\n",
      "Average loss for this update: 1.09\n",
      "New Record!\n",
      "Epoch  46/100 Batch   60/60 - Loss:  1.156, Seconds: 440.99\n",
      "Epoch  47/100 Batch   10/60 - Loss:  0.975, Seconds: 235.10\n",
      "Epoch  47/100 Batch   20/60 - Loss:  1.023, Seconds: 277.92\n",
      "Epoch  47/100 Batch   30/60 - Loss:  1.100, Seconds: 304.30\n",
      "Epoch  47/100 Batch   40/60 - Loss:  1.089, Seconds: 356.53\n",
      "Epoch  47/100 Batch   50/60 - Loss:  1.107, Seconds: 387.88\n",
      "Average loss for this update: 1.059\n",
      "New Record!\n",
      "Epoch  47/100 Batch   60/60 - Loss:  1.114, Seconds: 428.81\n",
      "Epoch  48/100 Batch   10/60 - Loss:  0.930, Seconds: 236.66\n",
      "Epoch  48/100 Batch   20/60 - Loss:  1.016, Seconds: 271.19\n",
      "Epoch  48/100 Batch   30/60 - Loss: 69.053, Seconds: 303.68\n",
      "Epoch  48/100 Batch   40/60 - Loss: 159.091, Seconds: 381.47\n",
      "Epoch  48/100 Batch   50/60 - Loss: 101.817, Seconds: 433.65\n",
      "Average loss for this update: 66.381\n",
      "No Improvement.\n",
      "Epoch  48/100 Batch   60/60 - Loss: 77.092, Seconds: 487.83\n",
      "Epoch  49/100 Batch   10/60 - Loss: 61.895, Seconds: 277.28\n",
      "Epoch  49/100 Batch   20/60 - Loss: 103.650, Seconds: 315.24\n",
      "Epoch  49/100 Batch   30/60 - Loss: 202.435, Seconds: 351.48\n",
      "Epoch  49/100 Batch   40/60 - Loss: 277.754, Seconds: 401.16\n",
      "Epoch  49/100 Batch   50/60 - Loss: 246.958, Seconds: 421.31\n",
      "Average loss for this update: 178.538\n",
      "No Improvement.\n",
      "Stopping Training.\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "learning_rate_decay = 0.95\n",
    "min_learning_rate = 0.0005\n",
    "display_step = 10 # Check training loss after every 10 batches\n",
    "stop_early = 0 \n",
    "stop = 2 # If the update loss does not decrease in 3 consecutive update checks, stop training\n",
    "per_epoch = 1 # Make 3 update checks per epoch\n",
    "update_check = (len(sampledSortedText)//batchSize//per_epoch)-10\n",
    "\n",
    "update_loss = 0 \n",
    "batch_loss = 0\n",
    "summary_update_loss = [] # Record the update losses for saving improvements in the model\n",
    "paddingToken = wordToIntDict[embedding.specialTokens['PADDING']]\n",
    "checkpoint = \"./best_model.ckpt\" \n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # If we want to continue training a previous session\n",
    "    #loader = tf.train.import_meta_graph(\"./\" + checkpoint + '.meta')\n",
    "    #loader.restore(sess, checkpoint)\n",
    "    \n",
    "    for epoch_i in range(1, epochs+1):\n",
    "        update_loss = 0\n",
    "        batch_loss = 0\n",
    "        for batch_i, (summaries_batch, texts_batch, summaries_lengths, texts_lengths) in enumerate(\n",
    "                BatchDataGenerator.generateBatches(sampledSortedSummaries, sampledSortedText, batchSize, paddingToken)):\n",
    "            start_time = time.time()\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: texts_batch,\n",
    "                 targets: summaries_batch,\n",
    "                 lr: learningRate,\n",
    "                 summary_length: summaries_lengths,\n",
    "                 text_length: texts_lengths,\n",
    "                 dropout_rate: dropoutRate})\n",
    "\n",
    "            batch_loss += loss\n",
    "            update_loss += loss\n",
    "            end_time = time.time()\n",
    "            batch_time = end_time - start_time\n",
    "\n",
    "            if (batch_i+1) % display_step == 0 and batch_i > 0:\n",
    "                print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'\n",
    "                      .format(epoch_i,\n",
    "                              epochs, \n",
    "                              batch_i+1, \n",
    "                              len(sampledSortedText) // batchSize, \n",
    "                              batch_loss / display_step, \n",
    "                              batch_time*display_step))\n",
    "                batch_loss = 0\n",
    "\n",
    "            if (batch_i+1) % update_check == 0 and batch_i > 0:\n",
    "                print(\"Average loss for this update:\", round(update_loss/update_check,3))\n",
    "                summary_update_loss.append(update_loss)\n",
    "                \n",
    "                # If the update loss is at a new minimum, save the model\n",
    "                if update_loss <= min(summary_update_loss):\n",
    "                    print('New Record!') \n",
    "                    stop_early = 0\n",
    "                    saver = tf.train.Saver() \n",
    "                    saver.save(sess, checkpoint)\n",
    "\n",
    "                else:\n",
    "                    print(\"No Improvement.\")\n",
    "                    stop_early += 1\n",
    "                    if stop_early == stop:\n",
    "                        break\n",
    "                update_loss = 0\n",
    "            \n",
    "                    \n",
    "        # Reduce learning rate, but not below its minimum value\n",
    "        learningRate *= learning_rate_decay\n",
    "        if learningRate < min_learning_rate:\n",
    "            learningRate = min_learning_rate\n",
    "        \n",
    "        if stop_early == stop:\n",
    "            print(\"Stopping Training.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[656, 7915, 11957, 11958, 1151, 2521, 1220, 1010, 7906, 286, 814, 4107, 11959, 886, 800, 11960, 172, 3010, 2979, 886, 4384, 11961, 1698, 7197, 172, 1254, 352, 11962, 2012, 10, 771, 396, 239, 849, 2852, 773, 1593, 3288, 402, 172, 1220, 8928, 4276, 1864, 3959, 2526, 69, 7906, 11957, 4205, 1151, 1136, 4109, 6403, 4095, 886, 2467, 370, 1010, 1151, 4107, 11959, 6403, 1392, 11963, 372, 4242, 3085, 718, 11360, 8115, 216, 2695, 10, 322, 11964, 11965, 1069, 666, 8125, 1366, 10, 11966, 504, 172, 651, 343, 788, 11957, 244, 10, 656, 1668, 1068, 9815, 4804, 644, 11967, 1879, 761, 1304, 7827, 4242, 3707, 892, 1151, 3898, 4256, 1318, 285, 11968, 147, 4242, 445, 7281, 406, 11969, 7827, 4242, 372, 886, 800, 3777, 814, 3689, 4269, 11970, 11968, 147, 4242, 760, 3105, 3898, 773, 11971, 5628, 1151, 9580, 11972, 2012, 11973, 3131, 4632, 3978, 2797, 2902, 257, 372, 1421, 238, 402, 240, 11974, 118, 1315, 3595, 3898, 7686, 11975, 4301, 2647, 11976, 286, 2315, 1220, 11977, 11916, 7402, 11978, 2647, 1705, 892, 1151, 352, 263, 383, 5757, 4223, 5522, 581, 11979, 286, 4257, 4352, 5522, 397, 11979, 11980, 4427, 11981, 3471, 263, 352, 3067, 11982, 11983, 1888, 886, 11984, 326, 5650, 585, 285, 3315, 221, 283, 4501, 224, 2467, 304, 3898, 6125, 95, 1151, 2938, 408, 4632, 3898, 3565, 11985, 290, 5422, 221, 10, 172, 843, 400, 5668, 2357, 1575, 1511, 1545, 202, 656, 68, 1304, 2325, 10, 283, 794, 7490, 4392, 1698, 7906, 290, 4177, 221, 2274, 172, 759, 465, 2462, 886, 1294, 2319, 2274, 2283, 876, 1676, 2469, 11986, 10, 3828, 283, 1644, 588, 535, 737, 370, 352, 845, 465, 2462, 3092, 11987, 6334, 5751, 3956, 3957, 1421, 216, 172, 256, 2012, 759, 2462, 1698, 2274, 10, 76, 368, 172, 738, 386, 11968, 1011, 5232, 2274, 737, 11957, 10683, 10, 11988, 1545, 85, 11989, 1311, 3037, 1318, 729, 282, 285, 1304, 11990, 1301, 282, 886, 704, 406, 1301, 535, 933, 934, 11991, 11992, 10678, 1182, 282, 1495, 1304, 11993, 11994, 892, 3978, 875, 911, 3985, 3883, 229, 3879, 656, 704, 3595, 3707, 4193, 892, 3978, 875, 11986, 4673, 11957, 286, 1209, 1668, 1068, 5256, 1354, 11607, 1235, 1949, 11995, 374, 923, 4632, 352, 895, 11957, 287, 383, 11996, 4675, 1129, 3765, 184, 5615, 5464, 68, 1293, 78, 5617, 7995, 9005, 5440, 78, 286, 11452, 1997, 5617, 1698, 7906, 3747, 11496, 1439, 10, 1151, 4674, 11997, 3978, 875, 264, 1311, 68, 11998, 1010, 4902, 224, 886, 4109, 8130, 3787, 1010, 3916, 11999, 8423, 283, 7424, 7906, 797, 1757, 1914, 5622, 440, 11976, 3978, 2488, 2473, 10, 8423, 283, 3988, 12000, 3820, 1914, 3747, 4977, 419, 4740, 10418, 7319, 1527, 221, 229, 3898, 10, 1719, 426, 8589, 1341, 5476, 12001, 3898, 229, 2209, 3839, 1520, 773, 729, 5635, 10, 9005, 322, 915, 5617, 221, 8472, 229, 6856, 2354, 8030, 3898, 8008, 4977, 11975, 1331, 105, 11957, 285, 8005, 8006, 8007, 8008, 4358, 4680, 10085, 1135, 287, 11997, 745, 3978, 875, 4674, 1151, 12002, 3041, 1599, 1235, 11995, 1010, 118, 3373, 244, 10, 2496, 2351, 6403, 1392, 4242, 440, 3143, 4680, 760, 9746, 221, 8008, 322, 5109, 1280, 656, 1289, 1290, 244, 10, 12003, 105, 10, 4673, 1290, 3070, 12004, 57, 8282, 4680, 1151, 886, 1939, 1293, 184, 5615, 1572, 7906, 1899, 356, 7841, 1290, 395, 2, 1331, 6430, 12005, 2064, 7906, 11957, 31, 5464, 383, 4675, 8011, 1129, 3765, 1290, 2403, 2506, 183, 3765, 1293, 3245, 2283, 6325, 1331, 322, 2403, 12006, 2549, 7906, 3301, 3878, 1290, 10, 282, 1293, 7460, 7462, 3765, 7906, 1220, 1010, 566, 119, 8666, 11772, 2123, 11975, 5795, 5796, 4898, 994, 787, 119, 12007, 12008, 12009, 12010, 7078, 11773, 12011, 12012, 552, 1057, 12007, 12013, 11975, 432, 433, 155835]]\n"
     ]
    }
   ],
   "source": [
    "newsIndex = 165\n",
    "totalNewsCount = len(textToNumberSequence)\n",
    "testNews = [textToNumberSequence[newsIndex]]\n",
    "maxSummaryLength = len(news['Summary'][newsIndex])\n",
    "print(testNews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./best_model.ckpt\n",
      "- News:\n",
      " president viktor yanukovych defended government handling political crisis ukraine thursday saying fulfilled obligations opposition leaders stoking people anger gain opposition continues escalate situation encourage people maintain protests icy streets said address posted website think wrong must understand future state people political interests certain groups set higher existence ukraine yanukovych insisted government lived concrete agreements reached opposition try end crisis government fulfilled obligations agreements including adoption law amnesty guarantees freedom liberation persons arrested conflict said also appealed ukrainians everything peace normal life said regrets young people died confrontation earlier yanukovych office said president sick leave acute respiratory disease accompanied fever country parliament approved amnesty bill anti government protesters extraordinary session wednesday unacceptable conditions amnesty top legislator announced factions approved amnesty law opposition leaders dispute saying legislation rushed imposes unacceptable conditions amnesty come effect protesters must vacate seized government buildings unblock streets squares except peaceful protest actions taking place law says according state run ukrinform news agency sign protesters leaving kiev independence square maidan thursday despite political maneuvering bitter cold billboard square heart anti government protests since november registered 16 celsius 3 fahrenheit thursday afternoon 23 celsius 9 fahrenheit forecast evening coldest weather since protests began arseniy yatsenyuk head opposition fatherland party warned late wednesday fresh violence could erupt authorities try clear protesters depends way government act press peaceful protesters definitely trigger another spiral violence said people feel issue constitutional reform shift balance power away president toward parliament addressed said could even somehow calm situation ukraine another surge violence klitschko people want real change opposition leader vitali klitschko ukrainian democratic alliance reforms udar said supporters could stand behind move called end protests without real change beyond freeing 218 activists interior ministry says arrested people took streets want change situation klitschko said statement free people go home unacceptable cannot understood klitschko called yanukovych resign said departure power would logical step special session held tuesday wednesday parliament reconvene next tuesday opposition yet announced next move prime minister mykola azarov cabinet resigned tuesday hours parliament annulled draconian anti protest laws sparked violent confrontations police demonstrators president yet sign bill repealing anti protest laws udar urged yanukovych thursday let sick leave prevent living responsibilities recent clashes escalation weeks largely peaceful protests prompted yanukovych decision november spurn planned trade deal european union turn toward russia europe concern parliamentary assembly council europe thursday voiced deep concern situation ukraine resolution adopted body said government resignation repeal protest laws first step toward resolving crisis followed authorities opposition concrete steps resolve crisis peacefully democratically sanctions could imposed ukraine grave human rights violations continue maidan protest broken force said sanctions could include suspension voting rights resolution calls full investigation excessive disproportionate use violence police protesters said especially concerned credible reports torture maltreatment protesters police security forces responsible must held accountable said assembly also raised concern violence directed police extreme right wing protesters merkel calls kiev moscow call yanukovych wednesday german chancellor angela merkel praised dialogue opposing sides decision repeal controversial protest laws resignation government assumed responsibility part recent escalation crisis news release office said matter following agreements including amnesty continue ongoing dialogue come renewed violence merkel also spoke russian president vladimir putin office said readout call said urged putin push constructive results oriented dialogue government opposition tensions russia european union developments ukraine side accusing interference putin denied week moscow exerting undue influence ukraine yanukovych u turn november planned eu trade deal putin agreed 15 billion deal russia buy ukrainian debt moscow also agreed slash price ukraine pays gas putin said tuesday russia intended honor deal ukraine political crisis played cnn diana magnay reported kiev laura smith spark wrote london cnn victoria eastwood lindsay isaac stephanie halasz marilia brocchetto well journalist victoria butenko kiev contributed report\n",
      "\n",
      "\n",
      "- Actual Summary:\n",
      " viktor yanukovych says his government has fulfilled all its obligations yanukovych is out on sick leave after an acute respiratory disease his office says protesters remain in the streets despite a new amnesty law and biting cold the amnesty law says protesters must vacate seized buildings and unblock streets\n",
      "\n",
      "\n",
      "- Predicted Summary:\n",
      " new the united states are deeply disturbed by the new cabinet says the state will keep state deadline the controversial controversial a government visit resolution will keep the first nations games at iran new hampshire legal government has already mostly moderates\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"./best_model.ckpt\"\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "    input_data = loaded_graph.get_tensor_by_name('inputData:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    text_length = loaded_graph.get_tensor_by_name('inputTextLengths:0')\n",
    "    summary_length = loaded_graph.get_tensor_by_name('inputSummaryLengths:0')\n",
    "    dropout_rate = loaded_graph.get_tensor_by_name('dropoutRate:0')\n",
    "    #Multiply by batch_size to match the model's input parameters\n",
    "    for i, text in enumerate(testNews):\n",
    "        answer_logits = sess.run(logits, {input_data: [text]*batchSize, \n",
    "                                          summary_length: [maxSummaryLength], #summary_length: [np.random.randint(5,8)], \n",
    "                                          text_length: [len(text)]*batchSize,\n",
    "                                          dropout_rate: 1.0})[0] \n",
    "        # Remove the padding from the summaries\n",
    "        pad = wordToIntDict[\"<PAD>\"] \n",
    "        #print('- News:\\n\\r {}\\n\\r\\n\\r'.format(\" \".join([intToWordDict[j] for j in testNews[i] if j != pad])))\n",
    "        print('- News:\\n\\r {}\\n\\r\\n\\r'.format(news['Text'][newsIndex]))\n",
    "        print('- Actual Summary:\\n\\r {}\\n\\r\\n\\r'.format(news['Summary'][newsIndex]))\n",
    "        print('- Predicted Summary:\\n\\r {}\\n\\r\\n\\r'.format(\" \".join([intToWordDict[j] for j in answer_logits if j != pad])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
